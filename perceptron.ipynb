{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perceptron algorithm is a binary classification and only works when the data is linearly separable.  \n",
    "The output is obtained by thresholding a linear function of the input: the parameters of the algorithm are the coefficients of this linear function.  \n",
    "This will produce a hyperplane that separate classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperplane define as a set of x that satisfy the function:\n",
    "\n",
    "<center>\n",
    "\n",
    "$H = {x: w^t x+b=0}$\n",
    "\n",
    "</center>\n",
    "\n",
    "Where $w$ is the weight and $b$ is bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to predict the classes:  \n",
    "We look at the sign of the function  \n",
    "<center>\n",
    "\n",
    "$w^tx+b$\n",
    "\n",
    "</center>\n",
    "\n",
    "If the values is greater than $0$ then it belong to one class and if the value is less than $0$ it belong to the other one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learning both $w$ and $b$ is hard so we shifted everything up by adding one additional constand dimension, therefore:\n",
    "<center>\n",
    "\n",
    "$x$ becomes $\\begin{bmatrix} \\mathbf{x} \\\\ 1  \\end{bmatrix}$  \n",
    "\n",
    "$w$ become $\\begin{bmatrix} \\mathbf{w} \\\\ b  \\end{bmatrix} $\n",
    "\n",
    "</center>  \n",
    "\n",
    "And we know that:\n",
    "\n",
    "<center>\n",
    "\n",
    "$\\begin{bmatrix} \\mathbf{x} \\\\ 1  \\end{bmatrix}^\\top \\begin{bmatrix} \\mathbf{w} \\\\ b  \\end{bmatrix} = \\mathbf{w}^\\top \\mathbf{x} + b$\n",
    "\n",
    "</center>\n",
    "\n",
    "This allow us to simplify the function for the hyperplane as:\n",
    "\n",
    "<center>\n",
    "\n",
    "$H = x: w^t x=0$\n",
    "\n",
    "</center>\n",
    "\n",
    "And the prediction output will be:\n",
    "\n",
    "<center>\n",
    "\n",
    "$w^tb$\n",
    "\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How the algorithm work:  \n",
    "\n",
    "1. Initialize $\\vec{w}=0$\n",
    "2. For every iteration set the number of error to 0\n",
    "3. Going through all the point and make sure that $y  w^tx \\geq 0$\n",
    "4. If not we will update the weight $\\vec{w}$ as $\\vec{w}+y\\vec{x}$ and record the number of our error $err = err+1$\n",
    "5. If the amount of error is 0 at the end then the algorithm converge and it succeed in classify every point in our data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perceptron algorithm draft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "weight = 0\n",
    "\n",
    "def perceptron(data):\n",
    "    while True:\n",
    "        err = 0\n",
    "        for x, y in data:\n",
    "            ###The lecture from Cornell and the book we talk about approach and updat the weight different this code is follow what the prof said in the lecture video at cornell\n",
    "            if y*(np.dot(np.transpose(weight),x)) <= 0:\n",
    "                weight = weight + y * x\n",
    "                err += 1\n",
    "        if err == 0:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
